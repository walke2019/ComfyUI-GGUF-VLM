"""
ComfyUI-GGUF-VLM API Routes
æä¾›åç«¯ API ç«¯ç‚¹ï¼Œç”¨äºå‰ç«¯ JavaScript è°ƒç”¨
"""

import json
from aiohttp import web
from server import PromptServer
from .core.inference.nexa_engine import get_nexa_engine
from .core.model_loader import ModelLoader
from .utils.registry import RegistryManager


# æ³¨å†Œ API è·¯ç”±
@PromptServer.instance.routes.get("/gguf-vlm/refresh-models")
async def refresh_models(request):
    """
    åˆ·æ–°è¿œç¨‹ API æ¨¡å‹åˆ—è¡¨
    
    Query Parameters:
        base_url: API æœåŠ¡åœ°å€
        api_type: API ç±»å‹ (ollama, nexa, openai)
    
    Returns:
        JSON: {"success": bool, "models": list, "error": str}
    """
    try:
        # è·å–å‚æ•°
        base_url = request.query.get('base_url', 'http://127.0.0.1:11434')
        api_type = request.query.get('api_type', 'ollama').lower()
        
        # åˆ›å»ºå¼•æ“å¹¶è·å–æ¨¡å‹
        engine = get_nexa_engine(base_url)
        
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
        if not engine.is_service_available():
            return web.json_response({
                "success": False,
                "models": [],
                "error": f"Service not available at {base_url}"
            })
        
        # è·å–æ¨¡å‹åˆ—è¡¨
        models = engine.get_available_models(force_refresh=True)
        
        if not models:
            return web.json_response({
                "success": False,
                "models": [],
                "error": "No models found"
            })
        
        return web.json_response({
            "success": True,
            "models": models,
            "error": None
        })
        
    except Exception as e:
        return web.json_response({
            "success": False,
            "models": [],
            "error": str(e)
        })


# åˆ·æ–°æœ¬åœ°è§†è§‰æ¨¡å‹åˆ—è¡¨
@PromptServer.instance.routes.get("/gguf-vlm/refresh-local-vision-models")
async def refresh_local_vision_models(request):
    """
    åˆ·æ–°æœ¬åœ°è§†è§‰æ¨¡å‹åˆ—è¡¨
    
    Returns:
        JSON: {"success": bool, "models": list, "error": str}
    """
    try:
        # åˆ›å»ºåŠ è½½å™¨å’Œæ³¨å†Œè¡¨
        loader = ModelLoader()
        registry = RegistryManager()
        
        # è·å–æ‰€æœ‰æœ¬åœ°æ¨¡å‹
        all_local_models = loader.list_models()
        print(f"ğŸ“¦ Found {len(all_local_models)} local GGUF files")
        
        # è¿‡æ»¤è§†è§‰æ¨¡å‹
        local_models = []
        for model_file in all_local_models:
            model_info = registry.find_model_by_filename(model_file)
            # å¦‚æœæ˜¯è§†è§‰æ¨¡å‹æˆ–æœªçŸ¥æ¨¡å‹ï¼ˆå¯èƒ½æ˜¯è§†è§‰æ¨¡å‹ï¼‰
            if model_info is None or model_info.get('business_type') in ['image_analysis', 'video_analysis']:
                local_models.append(model_file)
        
        # è·å–å¯ä¸‹è½½çš„æ¨¡å‹
        image_models = registry.get_downloadable_models(business_type='image_analysis', model_loader=loader)
        video_models = registry.get_downloadable_models(business_type='video_analysis', model_loader=loader)
        
        # æ„å»ºåˆ†ç±»åˆ—è¡¨
        categorized_models = []
        
        if image_models:
            categorized_models.append("--- ğŸ–¼ï¸ å›¾åƒåˆ†ææ¨¡å‹ ---")
            categorized_models.extend([name for name, _ in image_models])
        
        if video_models:
            categorized_models.append("--- ğŸ¥ è§†é¢‘åˆ†ææ¨¡å‹ ---")
            categorized_models.extend([name for name, _ in video_models])
        
        if local_models:
            categorized_models.append("--- ğŸ’¾ æœ¬åœ°æ¨¡å‹ ---")
            categorized_models.extend(local_models)
        
        if not categorized_models:
            return web.json_response({
                "success": False,
                "models": [],
                "error": "No vision models found"
            })
        
        return web.json_response({
            "success": True,
            "models": categorized_models,
            "error": None
        })
        
    except Exception as e:
        return web.json_response({
            "success": False,
            "models": [],
            "error": str(e)
        })


# åˆ·æ–°æœ¬åœ°æ–‡æœ¬æ¨¡å‹åˆ—è¡¨
@PromptServer.instance.routes.get("/gguf-vlm/refresh-local-text-models")
async def refresh_local_text_models(request):
    """
    åˆ·æ–°æœ¬åœ°æ–‡æœ¬æ¨¡å‹åˆ—è¡¨
    
    Returns:
        JSON: {"success": bool, "models": list, "error": str}
    """
    try:
        # åˆ›å»ºåŠ è½½å™¨å’Œæ³¨å†Œè¡¨
        loader = ModelLoader()
        registry = RegistryManager()
        
        # è·å–æ‰€æœ‰æœ¬åœ°æ¨¡å‹
        all_local_models = loader.list_models()
        print(f"ğŸ“¦ Found {len(all_local_models)} local GGUF files")
        
        # è§†è§‰æ¨¡å‹å…³é”®è¯åˆ—è¡¨ï¼ˆç”¨äºæ’é™¤ï¼‰
        vision_keywords = [
            'llava', 'vision', 'multimodal', 'mm', 
            'clip', 'minicpm-v', 'phi-3-vision', 
            'internvl', 'cogvlm', 'mmproj'
        ]
        
        # ç‰¹å®šçš„è§†è§‰æ¨¡å‹æ¨¡å¼
        vision_patterns = [
            'qwen-vl', 'qwen2-vl', 'qwen2.5-vl', 'qwen3-vl',
            '-vl-', '_vl_', '.vl.',
        ]
        
        # è¿‡æ»¤æ–‡æœ¬æ¨¡å‹
        local_models = []
        for model_file in all_local_models:
            model_lower = model_file.lower()
            
            # é¦–å…ˆæ£€æŸ¥registryä¿¡æ¯
            model_info = registry.find_model_by_filename(model_file)
            if model_info:
                business_type = model_info.get('business_type')
                if business_type == 'text_generation':
                    local_models.append(model_file)
                    continue
                elif business_type in ['image_analysis', 'video_analysis']:
                    continue
            
            # ä½¿ç”¨å…³é”®è¯è¿‡æ»¤
            is_vision_model = False
            for pattern in vision_patterns:
                if pattern in model_lower:
                    is_vision_model = True
                    break
            
            if not is_vision_model:
                is_vision_model = any(keyword in model_lower for keyword in vision_keywords)
            
            if not is_vision_model:
                local_models.append(model_file)
        
        # è·å–å¯ä¸‹è½½çš„æ–‡æœ¬æ¨¡å‹
        downloadable = registry.get_downloadable_models(business_type='text_generation', model_loader=loader)
        downloadable_names = [name for name, _ in downloadable]
        
        # åˆå¹¶åˆ—è¡¨
        all_models = local_models + downloadable_names
        
        if not all_models:
            return web.json_response({
                "success": False,
                "models": [],
                "error": "No text models found"
            })
        
        return web.json_response({
            "success": True,
            "models": all_models,
            "error": None
        })
        
    except Exception as e:
        return web.json_response({
            "success": False,
            "models": [],
            "error": str(e)
        })
