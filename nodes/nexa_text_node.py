"""
Nexa SDK Text Node - ä½¿ç”¨ Nexa SDK æœåŠ¡çš„æ–‡æœ¬ç”ŸæˆèŠ‚ç‚¹
æ”¯æŒæœ¬åœ°æ¨¡å‹è·¯å¾„ç®¡ç†ã€è‡ªåŠ¨ä¸‹è½½å’Œä¸ ComfyUI çš„ /models/LLM ç›®å½•é›†æˆ
"""

import re
import os
from typing import Tuple
from comfy.comfy_types import IO

# å°è¯•å¯¼å…¥è·¯å¾„é…ç½®
try:
    from ..config.paths import PathConfig
    HAS_PATH_CONFIG = True
except:
    HAS_PATH_CONFIG = False
    print("âš ï¸  PathConfig not available, using default paths")

from ..core.inference.nexa_engine import get_nexa_engine


# Nexa SDK é¢„è®¾æ¨¡å‹åˆ—è¡¨
# æ ¼å¼: author/model-name:quant
# ä½¿ç”¨å‰éœ€è¦å…ˆè¿è¡Œ: nexa pull <model-name>
PRESET_MODELS = [
    "Custom (è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹ ID)",
    "DavidAU/Qwen3-8B-64k-Josiefied-Uncensored-HORROR-Max-GGUF:Q6_K",
    "mradermacher/Huihui-Qwen3-4B-Thinking-2507-abliterated-GGUF:Q8_0",
    "prithivMLmods/Qwen3-4B-2507-abliterated-GGUF:Q8_0",
    "mradermacher/Qwen3-4B-Thinking-2507-Uncensored-Fixed-GGUF:Q8_0",
    "mradermacher/Qwen3-Short-Story-Instruct-Uncensored-262K-ctx-4B-GGUF:Q8_0",
]

# HuggingFace URL åˆ°æ¨¡å‹ ID çš„æ˜ å°„
HUGGINGFACE_URL_MAPPING = {
    "https://huggingface.co/prithivMLmods/Qwen3-4B-2507-abliterated-GGUF/blob/main/Qwen3-4B-Instruct-2507-abliterated-GGUF/Qwen3-4B-Instruct-2507-abliterated.Q8_0.gguf": "ğŸ¤– prithivMLmods/Qwen3-4B-2507-abliterated-GGUF:Q8_0",
    
    "https://huggingface.co/mradermacher/Qwen3-4B-Thinking-2507-Uncensored-Fixed-GGUF/resolve/main/Qwen3-4B-Thinking-2507-Uncensored-Fixed.Q8_0.gguf": "ğŸ¤– mradermacher/Qwen3-4B-Thinking-2507-Uncensored-Fixed-GGUF:Q8_0",
    
    "https://huggingface.co/mradermacher/Qwen3-Short-Story-Instruct-Uncensored-262K-ctx-4B-GGUF/blob/main/Qwen3-Short-Story-Instruct-Uncensored-262K-ctx-4B.Q8_0.gguf": "ğŸ¤– mradermacher/Qwen3-Short-Story-Instruct-Uncensored-262K-ctx-4B-GGUF:Q8_0",
    
    "https://huggingface.co/Triangle104/Josiefied-Qwen3-4B-abliterated-v2-Q8_0-GGUF/blob/main/josiefied-qwen3-4b-abliterated-v2-q8_0.gguf": "ğŸ¤– Triangle104/Josiefied-Qwen3-4B-abliterated-v2-Q8_0-GGUF",
}


def parse_model_input(model_input: str) -> str:
    """
    è§£ææ¨¡å‹è¾“å…¥ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š
    1. æ¨¡å‹ ID: "user/repo:quantization"
    2. HuggingFace URL
    3. æœ¬åœ°æ–‡ä»¶å: "model.gguf"
    
    Returns:
        æ ‡å‡†åŒ–çš„æ¨¡å‹æ ‡è¯†ç¬¦
    """
    model_input = model_input.strip()
    
    # å¦‚æœæ˜¯ HuggingFace URLï¼Œè½¬æ¢ä¸ºæ¨¡å‹ ID
    if model_input.startswith("https://huggingface.co/"):
        if model_input in HUGGINGFACE_URL_MAPPING:
            return HUGGINGFACE_URL_MAPPING[model_input]
        
        # å°è¯•ä» URL ä¸­æå–æ¨¡å‹ä¿¡æ¯
        # æ ¼å¼: https://huggingface.co/user/repo/blob/main/file.gguf
        # æˆ–: https://huggingface.co/user/repo/resolve/main/file.gguf
        parts = model_input.replace("https://huggingface.co/", "").split("/")
        if len(parts) >= 2:
            user = parts[0]
            repo = parts[1]
            
            # æå–é‡åŒ–ç±»å‹ï¼ˆå¦‚æœæœ‰ï¼‰
            if len(parts) >= 4:
                filename = parts[-1]
                # ä»æ–‡ä»¶åæå–é‡åŒ–ç±»å‹ï¼Œå¦‚ Q8_0, Q6_K ç­‰
                import re
                quant_match = re.search(r'\.(Q\d+_[0K]|Q\d+)', filename, re.IGNORECASE)
                if quant_match:
                    quant = quant_match.group(1).upper()
                    return f"{user}/{repo}:{quant}"
            
            return f"{user}/{repo}"
    
    # ç›´æ¥è¿”å›ï¼ˆæ¨¡å‹ ID æˆ–æœ¬åœ°æ–‡ä»¶åï¼‰
    return model_input


class RemoteAPIConfig:
    """è¿œç¨‹ API é…ç½®èŠ‚ç‚¹ï¼ˆNexa/Ollamaï¼‰"""
    
    @staticmethod
    def get_available_models(base_url="http://127.0.0.1:11434", api_type="nexa"):
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        try:
            # å°è¯•å¤šä¸ªå¸¸ç”¨ç«¯å£
            ports_to_try = [40054, 11434, 11435]
            
            # å¦‚æœ base_url ä¸­æŒ‡å®šäº†ç«¯å£ï¼Œä¼˜å…ˆä½¿ç”¨
            if ':' in base_url.split('//')[-1]:
                try:
                    engine = get_nexa_engine(base_url)
                    if engine.is_service_available():
                        models = engine.get_available_models(force_refresh=False)
                        if models:
                            return models
                except:
                    pass
            
            # å°è¯•å¸¸ç”¨ç«¯å£
            for port in ports_to_try:
                try:
                    test_url = f"http://127.0.0.1:{port}"
                    engine = get_nexa_engine(test_url)
                    if engine.is_service_available():
                        models = engine.get_available_models(force_refresh=False)
                        if models:
                            return models
                except:
                    continue
            
            return ["(è¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®)"]
        except:
            return ["(è¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®)"]
    
    @classmethod
    def INPUT_TYPES(cls):
        # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆä¼šå°è¯•å¤šä¸ªç«¯å£ï¼‰
        available_models = cls.get_available_models()
        
        return {
            "required": {
                "base_url": ("STRING", {
                    "default": "http://127.0.0.1:11434",
                    "multiline": False,
                    "tooltip": "API æœåŠ¡åœ°å€ï¼ˆä¾‹å¦‚ï¼šhttp://127.0.0.1:40054ï¼‰"
                }),
                "api_type": (["Nexa SDK", "Ollama"], {
                    "default": "Ollama",
                    "tooltip": "API ç±»å‹"
                }),
                "model": (available_models, {
                    "default": available_models[0] if available_models else "(è¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®)",
                    "tooltip": "é€‰æ‹©æ¨¡å‹ï¼ˆç‚¹å‡»åˆ·æ–°æŒ‰é’®æ›´æ–°åˆ—è¡¨ï¼‰"
                }),
            },
            "optional": {
                "system_prompt": (IO.STRING, {
                    "default": "",
                    "multiline": True,
                    "tooltip": "ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰"
                }),
            }
        }
    
    RETURN_TYPES = ("TEXT_MODEL",)
    RETURN_NAMES = ("model_config",)
    FUNCTION = "configure_api"
    CATEGORY = "ğŸ¤– GGUF-VLM/ğŸ’¬ Text Models"
    
    def configure_api(
        self, 
        base_url: str,
        api_type: str,
        model: str,
        system_prompt: str = ""
    ):
        """é…ç½®è¿œç¨‹ API"""
        
        # æ˜ å°„ API ç±»å‹
        api_type_map = {
            "Nexa SDK": "nexa",
            "Ollama": "ollama"
        }
        api_key = api_type_map.get(api_type, "nexa")
        
        # åˆ›å»ºæˆ–è·å–å¼•æ“
        engine = get_nexa_engine(base_url)
        
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
        is_available = engine.is_service_available()
        
        if not is_available:
            error_msg = f"âš ï¸  {api_type} service is not available at {base_url}"
            print(error_msg)
            print(f"   Please make sure the service is running.")
            
            config = {
                "mode": "remote",
                "base_url": base_url,
                "api_type": api_key,
                "model_name": model,
                "system_prompt": system_prompt,
                "service_available": False,
                "error": error_msg
            }
            return (config,)
        
        # è·å–å¯ç”¨æ¨¡å‹
        available_models = engine.get_available_models(force_refresh=False)
        
        # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹
        if model and model.strip() and not model.startswith("("):
            # ç”¨æˆ·é€‰æ‹©äº†æœ‰æ•ˆçš„æ¨¡å‹
            selected_model = model.strip()
            print(f"   ä½¿ç”¨é€‰æ‹©çš„æ¨¡å‹: {selected_model}")
        elif available_models and available_models[0] and not available_models[0].startswith("("):
            # è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
            selected_model = available_models[0]
            print(f"   è‡ªåŠ¨é€‰æ‹©æ¨¡å‹: {selected_model}")
        else:
            selected_model = ""
            print(f"   âš ï¸  æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹ï¼Œè¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®")
        
        # åˆ›å»ºé…ç½®ï¼ˆä½¿ç”¨ TEXT_MODEL æ ¼å¼ï¼Œå…¼å®¹ TextGeneration èŠ‚ç‚¹ï¼‰
        config = {
            "mode": "remote",
            "base_url": base_url,
            "api_type": api_key,
            "model_name": selected_model,
            "system_prompt": system_prompt,
            "service_available": True,
            "available_models": available_models
        }
        
        print(f"âœ… {api_type} configured")
        print(f"   Service URL: {base_url}")
        print(f"   Model: {selected_model}")
        print(f"   Available models: {len(available_models)}")
        
        return (config,)


# RemoteTextGeneration èŠ‚ç‚¹å·²ç§»é™¤
# è¯·ä½¿ç”¨ unified_text_node.py ä¸­çš„ TextGeneration èŠ‚ç‚¹
# RemoteAPIConfig ç°åœ¨è¾“å‡º TEXT_MODEL ç±»å‹ï¼Œå¯ä»¥ç›´æ¥è¿æ¥åˆ° TextGeneration


class NexaServiceStatus:
    """Nexa SDK æœåŠ¡çŠ¶æ€æ£€æŸ¥èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        # è·å– LLM æ¨¡å‹ç›®å½•
        if HAS_PATH_CONFIG:
            default_models_dir = PathConfig.get_llm_models_path()
        else:
            import folder_paths
            default_models_dir = os.path.join(folder_paths.models_dir, "LLM", "GGUF")
            os.makedirs(default_models_dir, exist_ok=True)
        
        return {
            "required": {
                "base_url": ("STRING", {
                    "default": "http://127.0.0.1:11434",
                    "tooltip": "Nexa SDK æœåŠ¡åœ°å€ï¼ˆå¯é…ç½®ï¼‰"
                }),
                "models_dir": ("STRING", {
                    "default": default_models_dir,
                    "tooltip": "æœ¬åœ°æ¨¡å‹ç›®å½•"
                }),
                "refresh": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "åˆ·æ–°æ¨¡å‹åˆ—è¡¨"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("status", "remote_models", "local_models")
    FUNCTION = "check_status"
    CATEGORY = "ğŸ¤– GGUF-VLM/ğŸ› ï¸ Tools"
    OUTPUT_NODE = True
    
    def check_status(self, base_url: str, models_dir: str, refresh: bool = False):
        """æ£€æŸ¥æœåŠ¡çŠ¶æ€"""
        
        engine = get_nexa_engine(base_url, models_dir)
        
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
        is_available = engine.is_service_available()
        
        status_lines = []
        status_lines.append(f"Nexa SDK Service: {base_url}")
        status_lines.append(f"Models Directory: {models_dir}")
        status_lines.append("")
        
        if is_available:
            # è·å–è¿œç¨‹æ¨¡å‹åˆ—è¡¨
            remote_models = engine.get_available_models(force_refresh=refresh)
            
            status_lines.append(f"âœ… Service is AVAILABLE")
            status_lines.append(f"Found {len(remote_models)} remote model(s)")
            
            remote_models_str = "\n".join([f"  - {model}" for model in remote_models]) if remote_models else "  (none)"
        else:
            status_lines.append(f"âŒ Service is NOT AVAILABLE")
            status_lines.append("Please make sure the service is running.")
            remote_models_str = "Service unavailable"
        
        # è·å–æœ¬åœ°æ¨¡å‹åˆ—è¡¨
        local_models = engine.get_local_models()
        status_lines.append(f"Found {len(local_models)} local model(s)")
        
        local_models_str = "\n".join([f"  - {model}" for model in local_models]) if local_models else "  (none)"
        
        status = "\n".join(status_lines)
        
        print(status)
        print("\nRemote models:")
        print(remote_models_str)
        print("\nLocal models:")
        print(local_models_str)
        
        return (status, remote_models_str, local_models_str)


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "RemoteAPIConfig": RemoteAPIConfig,
    "NexaServiceStatus": NexaServiceStatus,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "RemoteAPIConfig": "ğŸŒ Remote API Config (Nexa/Ollama)",
    "NexaServiceStatus": "ğŸ“Š Service Status Check",
}
