"""
è¿œç¨‹è§†è§‰æ¨¡å‹èŠ‚ç‚¹
æ”¯æŒ LM Studioã€Ollama ç­‰ OpenAI å…¼å®¹ API çš„è§†è§‰æ¨¡å‹
"""

import os
import base64
import numpy as np
from io import BytesIO
from PIL import Image
from typing import List, Dict, Any, Optional
from comfy.comfy_types import IO

from ..core.inference.unified_api_engine import get_unified_api_engine
import requests


class RemoteVisionModelConfig:
    """è¿œç¨‹è§†è§‰æ¨¡å‹é…ç½®èŠ‚ç‚¹"""
    
    @staticmethod
    def get_remote_models(base_url="http://127.0.0.1:1234"):
        """è·å–è¿œç¨‹æ¨¡å‹åˆ—è¡¨"""
        try:
            ports = [1234, 11434, 8080]  # LM Studio, Ollama, Nexa
            for port in ports:
                try:
                    # OpenAI å…¼å®¹æ ¼å¼
                    url = f"http://127.0.0.1:{port}/v1/models"
                    response = requests.get(url, timeout=2)
                    if response.status_code == 200:
                        data = response.json()
                        if 'data' in data:
                            models = [model['id'] for model in data.get('data', [])]
                            if models:
                                return models
                except:
                    pass
                
                try:
                    # Ollama æ ¼å¼
                    url = f"http://127.0.0.1:{port}/api/tags"
                    response = requests.get(url, timeout=2)
                    if response.status_code == 200:
                        data = response.json()
                        models = [model['name'] for model in data.get('models', [])]
                        if models:
                            return models
                except:
                    continue
            return ["(è¯·å¯åŠ¨ LM Studio æœåŠ¡)"]
        except:
            return ["(è¯·å¯åŠ¨ LM Studio æœåŠ¡)"]
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "base_url": ("STRING", {
                    "default": "http://127.0.0.1:1234",
                    "multiline": False,
                    "tooltip": "API æœåŠ¡åœ°å€ï¼ˆLM Studio é»˜è®¤: 1234, Ollama: 11434ï¼‰"
                }),
                "api_type": (["LM Studio", "Ollama", "OpenAI Compatible"], {
                    "default": "LM Studio",
                    "tooltip": "API ç±»å‹"
                }),
                # ä½¿ç”¨ç©ºå…ƒç»„è¡¨ç¤ºåŠ¨æ€åˆ—è¡¨ï¼Œç”±å‰ç«¯ JavaScript æ§åˆ¶
                "model": ((), {
                    "tooltip": "è§†è§‰æ¨¡å‹åç§°ï¼ˆç‚¹å‡» ğŸ”„ Refresh Models æŒ‰é’®æ›´æ–°åˆ—è¡¨ï¼‰"
                }),
            },
            "optional": {
                "system_prompt": (IO.STRING, {
                    "default": "You are a helpful assistant that describes images accurately and in detail.",
                    "multiline": True,
                    "tooltip": "ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰"
                }),
            }
        }
    
    RETURN_TYPES = ("REMOTE_VISION_MODEL",)
    RETURN_NAMES = ("model_config",)
    FUNCTION = "configure"
    CATEGORY = "ğŸ¤– GGUF-VLM/ğŸ–¼ï¸ Vision Models"
    
    def configure(self, base_url: str, api_type: str, model: str, system_prompt: str = ""):
        """é…ç½®è¿œç¨‹è§†è§‰æ¨¡å‹"""
        print(f"\n{'='*80}")
        print(f" ğŸŒ Remote Vision Model Config")
        print(f"{'='*80}")
        
        api_type_map = {
            "LM Studio": "lmstudio",
            "Ollama": "ollama",
            "OpenAI Compatible": "openai"
        }
        api_type_key = api_type_map.get(api_type, "lmstudio")
        
        # è·å– API å¼•æ“æ£€æŸ¥æœåŠ¡
        engine = get_unified_api_engine(base_url, api_type_key)
        service_available = engine.is_service_available()
        
        if not service_available:
            print(f"âš ï¸  {api_type} æœåŠ¡ä¸å¯ç”¨: {base_url}")
            print(f"   è¯·ç¡®ä¿æœåŠ¡æ­£åœ¨è¿è¡Œ")
        else:
            print(f"âœ… {api_type} æœåŠ¡å·²è¿æ¥")
            print(f"   URL: {base_url}")
            print(f"   Model: {model}")
        
        config = {
            "mode": "remote_vision",
            "base_url": base_url,
            "api_type": api_type_key,
            "model_name": model,
            "system_prompt": system_prompt,
            "service_available": service_available
        }
        
        print(f"{'='*80}\n")
        return (config,)


class RemoteVisionAnalysis:
    """è¿œç¨‹è§†è§‰åˆ†æèŠ‚ç‚¹ - æ”¯æŒ LM Studio ç­‰è§†è§‰æ¨¡å‹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model_config": ("REMOTE_VISION_MODEL", {
                    "tooltip": "è¿œç¨‹è§†è§‰æ¨¡å‹é…ç½®"
                }),
                "prompt": (IO.STRING, {
                    "default": "Describe this image in detail.",
                    "multiline": True,
                    "tooltip": "ç”¨æˆ·æç¤ºè¯"
                }),
                "max_tokens": ("INT", {
                    "default": 1024,
                    "min": 1,
                    "max": 8192,
                    "step": 1,
                    "tooltip": "æœ€å¤§ç”Ÿæˆ token æ•°ï¼ˆ-1 è¡¨ç¤ºæ— é™åˆ¶ï¼‰"
                }),
                "temperature": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "æ¸©åº¦å‚æ•°"
                }),
                "timeout": ("INT", {
                    "default": 300,
                    "min": 60,
                    "max": 1800,
                    "step": 30,
                    "tooltip": "è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰- è§†è§‰æ¨¡å‹å¤„ç†å›¾åƒéœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®® 300-600 ç§’"
                }),
            },
            "optional": {
                "image": ("IMAGE", {
                    "tooltip": "è¾“å…¥å›¾åƒ"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("description",)
    FUNCTION = "analyze"
    CATEGORY = "ğŸ¤– GGUF-VLM/ğŸ–¼ï¸ Vision Models"
    OUTPUT_NODE = True
    
    def analyze(
        self,
        model_config: Dict[str, Any],
        prompt: str,
        max_tokens: int = 1024,
        temperature: float = 0.7,
        timeout: int = 300,
        image=None
    ):
        """åˆ†æå›¾åƒ"""
        print("\n" + "="*80)
        print(" ğŸ–¼ï¸ Remote Vision Analysis")
        print("="*80)
        
        # æ£€æŸ¥é…ç½®
        if not model_config.get("service_available", False):
            error_msg = f"âŒ æœåŠ¡ä¸å¯ç”¨: {model_config.get('base_url', 'unknown')}"
            print(error_msg)
            return (error_msg,)
        
        if image is None:
            error_msg = "âŒ è¯·æä¾›è¾“å…¥å›¾åƒ"
            print(error_msg)
            return (error_msg,)
        
        base_url = model_config["base_url"]
        api_type = model_config["api_type"]
        model_name = model_config.get("model_name", "")
        system_prompt = model_config.get("system_prompt", "")
        
        print(f"ğŸŒ API: {api_type}")
        print(f"ğŸ“ URL: {base_url}")
        print(f"ğŸ¤– Model: {model_name}")
        
        # å°†å›¾åƒè½¬æ¢ä¸º base64
        image_base64 = self._image_to_base64(image)
        print(f"ğŸ“· å›¾åƒå·²ç¼–ç  (base64)")
        
        # è·å– API å¼•æ“
        engine = get_unified_api_engine(base_url, api_type)
        
        # æ„å»ºæ¶ˆæ¯ï¼ˆOpenAI Vision API æ ¼å¼ï¼‰
        messages = []
        
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        
        # è§†è§‰æ¶ˆæ¯æ ¼å¼
        user_content = [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{image_base64}"
                }
            },
            {
                "type": "text",
                "text": prompt
            }
        ]
        
        messages.append({"role": "user", "content": user_content})
        
        print(f"\nğŸ’¬ æ­£åœ¨åˆ†æå›¾åƒ...")
        print(f"   Prompt: {prompt[:50]}...")
        print(f"   Max tokens: {max_tokens}")
        print(f"   Temperature: {temperature}")
        print(f"   Timeout: {timeout} ç§’")
        
        try:
            # è°ƒç”¨ APIï¼ˆè§†è§‰æ¨¡å‹éœ€è¦æ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼‰
            response = engine.chat_completion(
                model=model_name,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens if max_tokens > 0 else 4096,
                stream=False,
                timeout=timeout  # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„è¶…æ—¶æ—¶é—´
            )
            
            # æå–ç»“æœ
            result = response['choices'][0]['message']['content']
            result = result.strip()
            
            print(f"\nâœ… åˆ†æå®Œæˆ ({len(result)} å­—ç¬¦)")
            print(f"   é¢„è§ˆ: {result[:100]}...")
            print("="*80 + "\n")
            
            return (result,)
        
        except Exception as e:
            error_msg = f"âŒ åˆ†æå¤±è´¥: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            return (error_msg,)
    
    def _image_to_base64(self, image) -> str:
        """å°† ComfyUI å›¾åƒå¼ é‡è½¬æ¢ä¸º base64 å­—ç¬¦ä¸²"""
        # è½¬æ¢ tensor åˆ° numpy
        img_array = image.cpu().numpy()
        
        # å¤„ç†æ‰¹æ¬¡ç»´åº¦
        if img_array.ndim == 4:
            img_array = img_array[0]  # å–ç¬¬ä¸€å¼ å›¾åƒ
        
        # è½¬æ¢åˆ° 0-255 èŒƒå›´
        img_array = np.clip(255.0 * img_array, 0, 255).astype(np.uint8)
        
        # åˆ›å»º PIL Image
        img = Image.fromarray(img_array)
        
        # è½¬æ¢ä¸º base64
        buffer = BytesIO()
        img.save(buffer, format="PNG")
        buffer.seek(0)
        
        return base64.b64encode(buffer.read()).decode('utf-8')


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "RemoteVisionModelConfig": RemoteVisionModelConfig,
    "RemoteVisionAnalysis": RemoteVisionAnalysis,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "RemoteVisionModelConfig": "ğŸŒ Remote Vision Model Config (LM Studio/Ollama)",
    "RemoteVisionAnalysis": "ğŸ–¼ï¸ Remote Vision Analysis",
}
