# ğŸ”§ æ•…éšœæ’æŸ¥æŒ‡å—

## â“ é—®é¢˜ï¼šåœ¨ ComfyUI ä¸­çœ‹ä¸åˆ°é¢„è®¾æ¨¡å‹

### ç—‡çŠ¶
- èŠ‚ç‚¹ä¸‹æ‹‰èœå•ä¸­æ²¡æœ‰ `[â¬‡ï¸ Abliterated Models]` å¼€å¤´çš„æ¨¡å‹
- åªæ˜¾ç¤º "No models found"
- æˆ–è€…åªæ˜¾ç¤ºæœ¬åœ°å·²æœ‰çš„æ¨¡å‹

### è§£å†³æ–¹æ¡ˆ

#### 1. æ£€æŸ¥æ’ä»¶æ˜¯å¦æ­£ç¡®åŠ è½½

**æŸ¥çœ‹ ComfyUI å¯åŠ¨æ—¥å¿—**ï¼Œåº”è¯¥çœ‹åˆ°ï¼š
```
ğŸ“¦ ComfyUI-GGUF-VLM loaded: XX nodes available
   ğŸ’¬ Text Models: Text-to-Text generation (Qwen3, LLaMA3, etc.)
   ğŸ–¼ï¸ Vision Models: Image-Text-to-Text analysis (Qwen2.5-VL, LLaVA, etc.)
   ğŸ› ï¸ Tools: System prompts, model management, service status
```

å¦‚æœæ²¡æœ‰çœ‹åˆ°è¿™ä¸ªä¿¡æ¯ï¼š
- æ’ä»¶å¯èƒ½æ²¡æœ‰æ­£ç¡®å®‰è£…
- æ£€æŸ¥æ˜¯å¦æœ‰ Python é”™è¯¯

#### 2. æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…

```bash
cd /home/ComfyUI/custom_nodes/ComfyUI-GGUF-VLM
pip install -r requirements.txt
```

å¿…éœ€çš„ä¾èµ–ï¼š
- `pyyaml` - ç”¨äºè¯»å–æ¨¡å‹é…ç½®
- `huggingface_hub` - ç”¨äºä¸‹è½½æ¨¡å‹
- `tqdm` - ä¸‹è½½è¿›åº¦æ¡

#### 3. è¿è¡Œè¯Šæ–­è„šæœ¬

```bash
cd /home/ComfyUI/custom_nodes/ComfyUI-GGUF-VLM/Test
python3 debug_node_models.py
```

åº”è¯¥çœ‹åˆ°ï¼š
```
âœ… é…ç½®æ­£ç¡®ï¼

ğŸ“¦ å¯ä¸‹è½½æ¨¡å‹åˆ—è¡¨ (å…± 3 ä¸ª):
â­ [â¬‡ï¸ Abliterated Models] Huihui-Qwen3-8B-abliterated-v2.Q8_0.gguf
â­ [â¬‡ï¸ Abliterated Models] Huihui-Qwen3-4B-Instruct-2507-abliterated.Q8_0.gguf
â­ [â¬‡ï¸ Abliterated Models] gemma-3-4b-abliterated.Q8_0.gguf
```

#### 4. æ£€æŸ¥é…ç½®æ–‡ä»¶

ç¡®è®¤ `model_registry.yaml` å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®ï¼š

```bash
cd /home/ComfyUI/custom_nodes/ComfyUI-GGUF-VLM
cat model_registry.yaml | grep "text_generation"
```

åº”è¯¥çœ‹åˆ° `business_type: text_generation`

#### 5. é‡å¯ ComfyUI

æœ‰æ—¶éœ€è¦å®Œå…¨é‡å¯ ComfyUI æ‰èƒ½åŠ è½½æ–°é…ç½®ï¼š

```bash
# åœæ­¢ ComfyUI
# é‡æ–°å¯åŠ¨ ComfyUI
```

#### 6. æ£€æŸ¥ Python è·¯å¾„

ç¡®ä¿ ComfyUI ä½¿ç”¨çš„ Python ç¯å¢ƒå·²å®‰è£…ä¾èµ–ï¼š

```bash
# æŸ¥çœ‹ ComfyUI ä½¿ç”¨çš„ Python
which python3

# åœ¨è¯¥ Python ç¯å¢ƒä¸­å®‰è£…ä¾èµ–
python3 -m pip install -r requirements.txt
```

## â“ é—®é¢˜ï¼šæ¨¡å‹ä¸‹è½½å¤±è´¥

### ç—‡çŠ¶
- é€‰æ‹©æ¨¡å‹åè¿è¡Œå·¥ä½œæµæŠ¥é”™
- æç¤º "Failed to download model"
- ä¸‹è½½é€Ÿåº¦å¾ˆæ…¢æˆ–è¶…æ—¶

### è§£å†³æ–¹æ¡ˆ

#### 1. æ£€æŸ¥ç½‘ç»œè¿æ¥

```bash
# æµ‹è¯•æ˜¯å¦èƒ½è®¿é—® HuggingFace
ping huggingface.co

# æˆ–ä½¿ç”¨ curl æµ‹è¯•
curl -I https://huggingface.co
```

#### 2. ä½¿ç”¨é•œåƒç«™ï¼ˆä¸­å›½ç”¨æˆ·ï¼‰

ç¼–è¾‘ `~/.bashrc` æˆ– `~/.zshrc`ï¼š

```bash
export HF_ENDPOINT=https://hf-mirror.com
```

ç„¶åé‡å¯ç»ˆç«¯æˆ–ï¼š
```bash
source ~/.bashrc
```

#### 3. æ‰‹åŠ¨ä¸‹è½½

å¦‚æœè‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼Œä½¿ç”¨æ‰‹åŠ¨ä¸‹è½½ï¼š

```bash
cd /home/ComfyUI/models/LLM/

# ä¸‹è½½æ¨¡å‹
wget https://huggingface.co/mradermacher/Huihui-Qwen3-8B-abliterated-v2-GGUF/resolve/main/Huihui-Qwen3-8B-abliterated-v2.Q8_0.gguf
```

#### 4. æ£€æŸ¥ç£ç›˜ç©ºé—´

```bash
df -h /home/ComfyUI/models/LLM/
```

ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´ï¼ˆè‡³å°‘ 10GBï¼‰

## â“ é—®é¢˜ï¼šæ¨¡å‹åŠ è½½å¤±è´¥

### ç—‡çŠ¶
- æ¨¡å‹ä¸‹è½½æˆåŠŸä½†æ— æ³•åŠ è½½
- æç¤º "Model not found"
- æç¤º llama-cpp-python ç›¸å…³é”™è¯¯

### è§£å†³æ–¹æ¡ˆ

#### 1. æ£€æŸ¥ llama-cpp-python å®‰è£…

```bash
python3 -c "import llama_cpp; print(llama_cpp.__version__)"
```

å¦‚æœæŠ¥é”™ï¼Œé‡æ–°å®‰è£…ï¼š

```bash
# CPU ç‰ˆæœ¬
pip install llama-cpp-python

# GPU ç‰ˆæœ¬ (CUDA)
CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python --force-reinstall --no-cache-dir
```

#### 2. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§

```bash
cd /home/ComfyUI/models/LLM/
ls -lh *.gguf

# æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦æ­£ç¡®
# Huihui-Qwen3-8B: åº”è¯¥çº¦ 8.5GB
# Huihui-Qwen3-4B: åº”è¯¥çº¦ 4.0GB
# Gemma-3-4B: åº”è¯¥çº¦ 4.0GB
```

å¦‚æœæ–‡ä»¶å¤§å°ä¸å¯¹ï¼Œé‡æ–°ä¸‹è½½ã€‚

#### 3. æ£€æŸ¥æ–‡ä»¶æƒé™

```bash
chmod 644 /home/ComfyUI/models/LLM/*.gguf
```

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½æ— æ³•è§£å†³é—®é¢˜ï¼š

1. **æŸ¥çœ‹ ComfyUI æ§åˆ¶å°å®Œæ•´é”™è¯¯ä¿¡æ¯**
2. **è¿è¡Œè¯Šæ–­è„šæœ¬å¹¶ä¿å­˜è¾“å‡º**ï¼š
   ```bash
   cd /home/ComfyUI/custom_nodes/ComfyUI-GGUF-VLM/Test
   python3 debug_node_models.py > debug_output.txt 2>&1
   ```
3. **æ£€æŸ¥ Python ç‰ˆæœ¬**ï¼š
   ```bash
   python3 --version
   ```
4. **æä¾›ä»¥ä¸Šä¿¡æ¯åˆ° GitHub Issues**

## ğŸ” å¿«é€Ÿè¯Šæ–­å‘½ä»¤

ä¸€é”®è¿è¡Œæ‰€æœ‰è¯Šæ–­ï¼š

```bash
cd /home/ComfyUI/custom_nodes/ComfyUI-GGUF-VLM

echo "=== Python ç‰ˆæœ¬ ==="
python3 --version

echo -e "\n=== ä¾èµ–æ£€æŸ¥ ==="
python3 -c "import yaml; import huggingface_hub; import tqdm; print('âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…')" 2>&1

echo -e "\n=== é…ç½®æ–‡ä»¶æ£€æŸ¥ ==="
python3 Test/debug_node_models.py

echo -e "\n=== æ¨¡å‹ç›®å½• ==="
ls -lh /home/ComfyUI/models/LLM/*.gguf 2>/dev/null || echo "æš‚æ— æœ¬åœ°æ¨¡å‹"
```

ä¿å­˜ä¸º `diagnose.sh` å¹¶è¿è¡Œï¼š
```bash
chmod +x diagnose.sh
./diagnose.sh
```
